{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>autograd</font>\n",
    "Tensor 訓練網路很方便, 但從 3.1 節最後的線性回歸實例來看, 反向傳播過程需要手動實現. 這對線性回歸這種比較簡單的模型來說還可以接受, **但實際使用中經常出現非常複雜的網路結構, 此時如果手動實現反向傳播, 不僅費時費力, 而且容易出錯, 難以檢查!** [**torch.autograd**](https://pytorch.org/docs/stable/autograd.html) 就是為方便使用者使用, 專門開發的一套自動求導引擎, 它能夠根據輸入和正向傳播過程, 自動建置計算圖, 並且執行反向傳播.\n",
    "\n",
    "計算圖 (<font color='brown'>Computation Graph</font>) 是現代深度學習架構 (<font color='brown'>如 PyTorch 和 Tensorflow 等</font>) 的核心, 它為自動求導演算法 - 反向傳播 (Back Propogation) 提供了理論支援, 了解計算圖在實際寫程式過程中會有相當大的幫助. 本節會提到一些基礎的計算圖知識, 但並不要求讀者事先對此有深入了解. 關於計算圖的基礎知識推薦閱讀 [**Christopher Olah**](https://ai.google/research/people/ChristopherOlah) 的文章.\n",
    "\n",
    "### <font color='darkgreen'>Variable</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
